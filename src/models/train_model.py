"""
train_model.py - Treino do Isolation Forest para DetecÃ§Ã£o de Fraude
Fraud Detection Project - Fase 4

Este script treina um modelo de detecÃ§Ã£o de anomalias (Isolation Forest)
de forma NÃƒO SUPERVISIONADA, ou seja, sem usar o gabarito is_fraud.

FILOSOFIA:
- Isolation Forest aprende padrÃµes "normais" e detecta desvios
- NÃ£o precisa de labels (is_fraud) durante o treino
- Ideal para fraudes novas que nunca vimos antes

ESTRATÃ‰GIA:
- Usar apenas transaÃ§Ãµes NORMAIS para treino (para aprender o "normal")
- Testar em transaÃ§Ãµes mistas (normal + fraude)
- Avaliar quantas fraudes o modelo consegue detectar
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib
import os
import sys

# Adicionar path para importar mÃ³dulos
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from features.build_features import get_feature_columns


def load_processed_data():
    """Carrega dataset com features jÃ¡ criadas."""
    print("=" * 80)
    print("TREINO DO ISOLATION FOREST - FRAUD DETECTION")
    print("=" * 80)
    
    print("\nğŸ“‚ Carregando dados processados...")
    
    # Tentar diferentes caminhos
    possible_paths = [
        '../data/processed/transactions_with_features.csv',
        'data/processed/transactions_with_features.csv',
        '../../data/processed/transactions_with_features.csv'
    ]
    
    df = None
    # CORREÃ‡ÃƒO: Usar caminhos relativos ao script para robustez
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(script_dir))
    data_path = os.path.join(project_root, 'data', 'processed', 'transactions_with_features.csv')

    if os.path.exists(data_path):
        print(f"  âœ“ Arquivo encontrado: {data_path}")
        df = pd.read_csv(data_path)
    
    if df is None:
        print(f"\nâŒ ERRO: Arquivo de features nÃ£o encontrado em: {data_path}")
        print("Execute 'python src/eda_fraud_analysis.py' primeiro!")
        sys.exit(1)
    
    print(f"  âœ“ {len(df):,} transaÃ§Ãµes carregadas")
    print(f"  âœ“ Fraudes: {df['is_fraud'].sum():,} ({df['is_fraud'].mean()*100:.2f}%)")
    
    return df


def prepare_train_test_split(df, test_size=200_000, random_state=42):
    """
    Divide dados em treino e teste de forma estratificada.
    
    ESTRATÃ‰GIA:
    - Treino: 100k transaÃ§Ãµes (majoritariamente normais)
    - Teste: 200k transaÃ§Ãµes (com todas as fraudes para avaliaÃ§Ã£o robusta)
    
    Args:
        df: DataFrame completo
        test_size: Tamanho do conjunto de teste
        random_state: Seed para reprodutibilidade
    
    Returns:
        Tuple (X_train, X_test, y_train, y_test, test_metadata)
    """
    print("\nğŸ”€ Dividindo dados em treino e teste...")
    
    # Separar features e target
    feature_cols = get_feature_columns()
    
    X = df[feature_cols].copy()
    y = df['is_fraud'].copy()
    
    # Metadata para anÃ¡lise posterior (tipo de fraude, dificuldade)
    metadata_cols = ['transaction_id', 'user_id', 'fraud_type', 'fraud_difficulty', 'amount', 'timestamp']
    metadata = df[metadata_cols].copy()
    
    # Split estratificado (manter proporÃ§Ã£o de fraudes)
    train_size = len(df) - test_size
    
    X_train, X_test, y_train, y_test, meta_train, meta_test = train_test_split(
        X, y, metadata,
        test_size=test_size,
        random_state=random_state,
        stratify=y  # Importante: manter proporÃ§Ã£o de fraudes
    )
    
    print(f"  âœ“ Treino: {len(X_train):,} transaÃ§Ãµes ({y_train.sum()} fraudes)")
    print(f"  âœ“ Teste: {len(X_test):,} transaÃ§Ãµes ({y_test.sum()} fraudes)")
    
    return X_train, X_test, y_train, y_test, meta_test


def train_isolation_forest(X_train, contamination=0.01):
    """
    Treina o Isolation Forest.
    
    HIPERPARÃ‚METROS:
    - contamination: ProporÃ§Ã£o esperada de anomalias (0.01 = 1%)
      NOTA: Com as novas features (rapid_sequence, value_anomaly, combined_score),
      esperamos recall muito maior mesmo com contamination=1%
    - n_estimators: NÃºmero de Ã¡rvores (100 Ã© suficiente)
    - max_samples: Amostras por Ã¡rvore ('auto' = min(256, n_samples))
    - random_state: Seed para reprodutibilidade
    
    Args:
        X_train: Features de treino
        contamination: ProporÃ§Ã£o esperada de fraudes
    
    Returns:
        Modelo treinado
    """
    print(f"\nğŸ¤– Treinando Isolation Forest...")
    print(f"  - Contamination: {contamination} ({contamination*100:.2f}%)")
    print(f"  - N estimators: 100")
    print(f"  - Max samples: auto")
    print(f"  - Features: 13 (incluindo 3 novas!)")
    
    # Normalizar features (importante para Isolation Forest)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    
    # Treinar modelo
    model = IsolationForest(
        contamination=contamination,
        n_estimators=100,
        max_samples='auto',
        random_state=42,
        n_jobs=-1,  # Usar todos os cores
        verbose=0
    )
    
    model.fit(X_train_scaled)
    
    print("  âœ“ Modelo treinado com sucesso!")
    
    return model, scaler


def save_model(model, scaler):
    """
    Salva modelo e scaler para uso posterior.
    
    Args:
        model: Modelo treinado
        scaler: StandardScaler ajustado
    """
    print(f"\nğŸ’¾ Salvando modelo...")

    # --- INÃCIO DA CORREÃ‡ÃƒO ---
    # ConstrÃ³i o caminho para a pasta 'models' na raiz do projeto
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(script_dir))
    output_dir = os.path.join(project_root, 'models')
    # --- FIM DA CORREÃ‡ÃƒO ---

    # Criar diretÃ³rio se nÃ£o existir
    os.makedirs(output_dir, exist_ok=True)
    
    # Salvar modelo
    model_path = os.path.join(output_dir, 'isolation_forest.joblib')
    joblib.dump(model, model_path)
    print(f"  âœ“ Modelo salvo: {model_path}")
    
    # Salvar scaler
    scaler_path = os.path.join(output_dir, 'scaler.joblib')
    joblib.dump(scaler, scaler_path)
    print(f"  âœ“ Scaler salvo: {scaler_path}")
    
    # Salvar lista de features (para garantir ordem na API)
    feature_cols = get_feature_columns()
    features_path = os.path.join(output_dir, 'feature_columns.txt')
    with open(features_path, 'w') as f:
        f.write('\n'.join(feature_cols))
    print(f"  âœ“ Features salvas: {features_path}")


def quick_evaluation(model, scaler, X_test, y_test):
    """
    AvaliaÃ§Ã£o rÃ¡pida do modelo (detalhes na evaluate_model.py).
    
    Args:
        model: Modelo treinado
        scaler: StandardScaler
        X_test: Features de teste
        y_test: Labels de teste
    """
    print(f"\nğŸ“Š AvaliaÃ§Ã£o RÃ¡pida no Conjunto de Teste...")
    
    # Normalizar test set
    X_test_scaled = scaler.transform(X_test)
    
    # Fazer prediÃ§Ãµes (-1 = anomalia, 1 = normal)
    predictions = model.predict(X_test_scaled)
    
    # Converter para formato binÃ¡rio (1 = anomalia, 0 = normal)
    y_pred = (predictions == -1).astype(int)
    
    # Calcular mÃ©tricas bÃ¡sicas
    total_frauds = y_test.sum()
    detected_frauds = (y_pred[y_test == 1] == 1).sum()
    
    recall = detected_frauds / total_frauds if total_frauds > 0 else 0
    
    total_normal = (y_test == 0).sum()
    false_positives = (y_pred[y_test == 0] == 1).sum()
    fpr = false_positives / total_normal if total_normal > 0 else 0
    
    print(f"\n  ğŸ¯ Recall (Fraudes Detectadas): {recall*100:.1f}%")
    print(f"     - {detected_frauds}/{total_frauds} fraudes detectadas")
    
    print(f"\n  âš ï¸  Taxa de Falsos Positivos: {fpr*100:.2f}%")
    print(f"     - {false_positives:,} transaÃ§Ãµes normais marcadas como fraude")
    
    print(f"\n  ğŸ’¡ Para anÃ¡lise detalhada por tipo e dificuldade:")
    print(f"     Execute: python src/models/evaluate_model.py")


def main():
    """FunÃ§Ã£o principal."""
    
    # 1. Carregar dados
    df = load_processed_data()
    
    # 2. Dividir em treino/teste
    X_train, X_test, y_train, y_test, meta_test = prepare_train_test_split(df)
    
    # 3. Treinar modelo
    model, scaler = train_isolation_forest(X_train)
    
    # 4. Salvar modelo (agora salva no local correto)
    save_model(model, scaler)
    
    # 5. AvaliaÃ§Ã£o rÃ¡pida
    quick_evaluation(model, scaler, X_test, y_test)
    
    print("\n" + "=" * 80)
    print("âœ“ TREINO CONCLUÃDO COM SUCESSO!")
    print("=" * 80)
    print("\nğŸ“Œ PrÃ³ximos passos:")
    print("  1. AvaliaÃ§Ã£o detalhada: python src/models/evaluate_model.py")
    print("  2. Reconstruir imagem Docker: docker build -t fraud-api .")
    print("  3. Rodar contÃªiner: docker run -p 5000:5000 fraud-api")


if __name__ == '__main__':
    main()
