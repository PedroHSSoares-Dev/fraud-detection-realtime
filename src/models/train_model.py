"""
train_model.py - Treino do Isolation Forest para Detec√ß√£o de Fraude
Fraud Detection Project - Fase 4

Este script treina um modelo de detec√ß√£o de anomalias (Isolation Forest)
de forma N√ÉO SUPERVISIONADA, ou seja, sem usar o gabarito is_fraud.

FILOSOFIA:
- Isolation Forest aprende padr√µes "normais" e detecta desvios
- N√£o precisa de labels (is_fraud) durante o treino
- Ideal para fraudes novas que nunca vimos antes

ESTRAT√âGIA:
- Usar apenas transa√ß√µes NORMAIS para treino (para aprender o "normal")
- Testar em transa√ß√µes mistas (normal + fraude)
- Avaliar quantas fraudes o modelo consegue detectar
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib
import os
import sys

# Adicionar path para importar m√≥dulos
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from features.build_features import get_feature_columns


def load_processed_data():
    """Carrega dataset com features j√° criadas."""
    print("=" * 80)
    print("TREINO DO ISOLATION FOREST - FRAUD DETECTION")
    print("=" * 80)
    
    print("\nüìÇ Carregando dados processados...")
    
    # Tentar diferentes caminhos
    possible_paths = [
        '../data/processed/transactions_with_features.csv',
        'data/processed/transactions_with_features.csv',
        '../../data/processed/transactions_with_features.csv'
    ]
    
    df = None
    for path in possible_paths:
        if os.path.exists(path):
            print(f"  ‚úì Arquivo encontrado: {path}")
            df = pd.read_csv(path)
            break
    
    if df is None:
        print("\n‚ùå ERRO: Arquivo de features n√£o encontrado!")
        print("Execute 'python eda_fraud_analysis.py' primeiro!")
        sys.exit(1)
    
    print(f"  ‚úì {len(df):,} transa√ß√µes carregadas")
    print(f"  ‚úì Fraudes: {df['is_fraud'].sum():,} ({df['is_fraud'].mean()*100:.2f}%)")
    
    return df


def prepare_train_test_split(df, test_size=200_000, random_state=42):
    """
    Divide dados em treino e teste de forma estratificada.
    
    ESTRAT√âGIA:
    - Treino: 100k transa√ß√µes (majoritariamente normais)
    - Teste: 200k transa√ß√µes (com todas as fraudes para avalia√ß√£o robusta)
    
    Args:
        df: DataFrame completo
        test_size: Tamanho do conjunto de teste
        random_state: Seed para reprodutibilidade
    
    Returns:
        Tuple (X_train, X_test, y_train, y_test, test_metadata)
    """
    print("\nüîÄ Dividindo dados em treino e teste...")
    
    # Separar features e target
    feature_cols = get_feature_columns()
    
    X = df[feature_cols].copy()
    y = df['is_fraud'].copy()
    
    # Metadata para an√°lise posterior (tipo de fraude, dificuldade)
    metadata_cols = ['transaction_id', 'user_id', 'fraud_type', 'fraud_difficulty', 'amount', 'timestamp']
    metadata = df[metadata_cols].copy()
    
    # Split estratificado (manter propor√ß√£o de fraudes)
    train_size = len(df) - test_size
    
    X_train, X_test, y_train, y_test, meta_train, meta_test = train_test_split(
        X, y, metadata,
        test_size=test_size,
        random_state=random_state,
        stratify=y  # Importante: manter propor√ß√£o de fraudes
    )
    
    print(f"  ‚úì Treino: {len(X_train):,} transa√ß√µes ({y_train.sum()} fraudes)")
    print(f"  ‚úì Teste: {len(X_test):,} transa√ß√µes ({y_test.sum()} fraudes)")
    
    return X_train, X_test, y_train, y_test, meta_test


def train_isolation_forest(X_train, contamination=0.01):
    """
    Treina o Isolation Forest.
    
    HIPERPAR√ÇMETROS:
    - contamination: Propor√ß√£o esperada de anomalias (0.01 = 1%)
      NOTA: Com as novas features (rapid_sequence, value_anomaly, combined_score),
      esperamos recall muito maior mesmo com contamination=1%
    - n_estimators: N√∫mero de √°rvores (100 √© suficiente)
    - max_samples: Amostras por √°rvore ('auto' = min(256, n_samples))
    - random_state: Seed para reprodutibilidade
    
    Args:
        X_train: Features de treino
        contamination: Propor√ß√£o esperada de fraudes
    
    Returns:
        Modelo treinado
    """
    print(f"\nü§ñ Treinando Isolation Forest...")
    print(f"  - Contamination: {contamination} ({contamination*100:.2f}%)")
    print(f"  - N estimators: 100")
    print(f"  - Max samples: auto")
    print(f"  - Features: 13 (incluindo 3 novas!)")
    
    # Normalizar features (importante para Isolation Forest)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    
    # Treinar modelo
    model = IsolationForest(
        contamination=contamination,
        n_estimators=100,
        max_samples='auto',
        random_state=42,
        n_jobs=-1,  # Usar todos os cores
        verbose=0
    )
    
    model.fit(X_train_scaled)
    
    print("  ‚úì Modelo treinado com sucesso!")
    
    return model, scaler


def save_model(model, scaler, output_dir='../models'):
    """
    Salva modelo e scaler para uso posterior.
    
    Args:
        model: Modelo treinado
        scaler: StandardScaler ajustado
        output_dir: Diret√≥rio de sa√≠da
    """
    print(f"\nüíæ Salvando modelo...")
    
    # Criar diret√≥rio se n√£o existir
    os.makedirs(output_dir, exist_ok=True)
    
    # Salvar modelo
    model_path = os.path.join(output_dir, 'isolation_forest.joblib')
    joblib.dump(model, model_path)
    print(f"  ‚úì Modelo salvo: {model_path}")
    
    # Salvar scaler
    scaler_path = os.path.join(output_dir, 'scaler.joblib')
    joblib.dump(scaler, scaler_path)
    print(f"  ‚úì Scaler salvo: {scaler_path}")
    
    # Salvar lista de features (para garantir ordem na API)
    feature_cols = get_feature_columns()
    features_path = os.path.join(output_dir, 'feature_columns.txt')
    with open(features_path, 'w') as f:
        f.write('\n'.join(feature_cols))
    print(f"  ‚úì Features salvas: {features_path}")


def quick_evaluation(model, scaler, X_test, y_test):
    """
    Avalia√ß√£o r√°pida do modelo (detalhes na evaluate_model.py).
    
    Args:
        model: Modelo treinado
        scaler: StandardScaler
        X_test: Features de teste
        y_test: Labels de teste
    """
    print(f"\nüìä Avalia√ß√£o R√°pida no Conjunto de Teste...")
    
    # Normalizar test set
    X_test_scaled = scaler.transform(X_test)
    
    # Fazer predi√ß√µes (-1 = anomalia, 1 = normal)
    predictions = model.predict(X_test_scaled)
    
    # Converter para formato bin√°rio (1 = anomalia, 0 = normal)
    y_pred = (predictions == -1).astype(int)
    
    # Calcular m√©tricas b√°sicas
    total_frauds = y_test.sum()
    detected_frauds = (y_pred[y_test == 1] == 1).sum()
    
    recall = detected_frauds / total_frauds if total_frauds > 0 else 0
    
    total_normal = (y_test == 0).sum()
    false_positives = (y_pred[y_test == 0] == 1).sum()
    fpr = false_positives / total_normal if total_normal > 0 else 0
    
    print(f"\n  üéØ Recall (Fraudes Detectadas): {recall*100:.1f}%")
    print(f"     - {detected_frauds}/{total_frauds} fraudes detectadas")
    
    print(f"\n  ‚ö†Ô∏è  Taxa de Falsos Positivos: {fpr*100:.2f}%")
    print(f"     - {false_positives:,} transa√ß√µes normais marcadas como fraude")
    
    print(f"\n  üí° Para an√°lise detalhada por tipo e dificuldade:")
    print(f"     Execute: python evaluate_model.py")


def main():
    """Fun√ß√£o principal."""
    
    # 1. Carregar dados
    df = load_processed_data()
    
    # 2. Dividir em treino/teste
    X_train, X_test, y_train, y_test, meta_test = prepare_train_test_split(df)
    
    # 3. Treinar modelo
    model, scaler = train_isolation_forest(X_train)
    
    # 4. Salvar modelo
    save_model(model, scaler)
    
    # 5. Avalia√ß√£o r√°pida
    quick_evaluation(model, scaler, X_test, y_test)
    
    print("\n" + "=" * 80)
    print("‚úì TREINO CONCLU√çDO COM SUCESSO!")
    print("=" * 80)
    print("\nüìå Pr√≥ximos passos:")
    print("  1. Avalia√ß√£o detalhada: python evaluate_model.py")
    print("  2. Testar predi√ß√µes: python predict.py")
    print("  3. Deploy na API (Fase 5)")


if __name__ == '__main__':
    main()