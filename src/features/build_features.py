"""
build_features.py - Feature Engineering para Detec√ß√£o de Anomalias
Fraud Detection Project - Fase 3

Este m√≥dulo cont√©m fun√ß√µes para criar features que capturam mudan√ßas de comportamento.
Essas features transformam dados brutos em sinais detect√°veis de anomalia.

FILOSOFIA:
- Anomalias s√£o DESVIOS DE PADR√ÉO, n√£o valores absolutos
- Features devem comparar transa√ß√£o atual com hist√≥rico do usu√°rio
- Quanto mais contextual a feature, mais poderosa

Features Implementadas:
1. tempo_desde_ultima_tx_usuario (s)
2. media_gasto_7d_usuario (R$)
3. std_gasto_7d_usuario (R$)
4. distancia_tx_home_location (km)
5. tx_fora_horario_comum (0/1)
6. velocidade_entre_txs (km/h) - DETECTA TELEPORTE!
7. desvio_valor_do_padrao (z-score)
8. hora_do_dia (0-23)
9. dia_da_semana (0-6)
10. is_weekend (0/1)
"""

import pandas as pd
import numpy as np
from typing import Tuple
from datetime import timedelta
from geopy.distance import geodesic


def calculate_time_since_last_transaction(df: pd.DataFrame) -> pd.Series:
    """
    Calcula o tempo (em segundos) desde a √∫ltima transa√ß√£o do mesmo usu√°rio.
    
    DETECTA: Sondagem de cart√£o (m√∫ltiplas transa√ß√µes em segundos)
    
    Args:
        df: DataFrame com colunas 'user_id' e 'timestamp'
    
    Returns:
        Series com tempo em segundos (NaN para primeira transa√ß√£o do usu√°rio)
    """
    # Garantir que timestamp seja datetime
    df = df.copy()
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    # Ordenar por usu√°rio e timestamp
    df = df.sort_values(['user_id', 'timestamp'])
    
    # Calcular diferen√ßa de tempo dentro de cada usu√°rio
    df['prev_timestamp'] = df.groupby('user_id')['timestamp'].shift(1)
    df['time_since_last_tx'] = (df['timestamp'] - df['prev_timestamp']).dt.total_seconds()
    
    # Primeira transa√ß√£o de cada usu√°rio = NaN (substituir por valor alto, ex: 1 dia)
    df['time_since_last_tx'] = df['time_since_last_tx'].fillna(86400)  # 24h em segundos
    
    return df['time_since_last_tx']


def calculate_user_spending_stats(df: pd.DataFrame, window_days: int = 7) -> Tuple[pd.Series, pd.Series]:
    """
    Calcula m√©dia e desvio padr√£o de gasto do usu√°rio nos √∫ltimos N dias.
    
    DETECTA: Gasto s√∫bito (valor muito acima da m√©dia do usu√°rio)
    
    Args:
        df: DataFrame com colunas 'user_id', 'timestamp', 'amount'
        window_days: Janela de tempo em dias (padr√£o: 7)
    
    Returns:
        Tuple (m√©dia, desvio_padr√£o) de gasto do usu√°rio
    """
    df = df.copy()
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df = df.sort_values(['user_id', 'timestamp'])
    
    # Calcular m√©dia m√≥vel por usu√°rio (janela de tempo)
    df['user_avg_amount_7d'] = df.groupby('user_id')['amount'].transform(
        lambda x: x.rolling(window=window_days, min_periods=1).mean()
    )
    
    # Calcular desvio padr√£o m√≥vel
    df['user_std_amount_7d'] = df.groupby('user_id')['amount'].transform(
        lambda x: x.rolling(window=window_days, min_periods=1).std()
    )
    
    # Preencher NaN com m√©dia geral
    df['user_avg_amount_7d'] = df['user_avg_amount_7d'].fillna(df['amount'].mean())
    df['user_std_amount_7d'] = df['user_std_amount_7d'].fillna(df['amount'].std())
    
    return df['user_avg_amount_7d'], df['user_std_amount_7d']


def calculate_distance_from_home(df: pd.DataFrame) -> pd.Series:
    """
    Calcula dist√¢ncia (em km) entre localiza√ß√£o da transa√ß√£o e localiza√ß√£o "home" do usu√°rio.
    
    DETECTA: Teleporte geogr√°fico (transa√ß√£o longe de casa)
    
    L√ìGICA:
    - "Home" = localiza√ß√£o da primeira transa√ß√£o do usu√°rio (assumimos que √© casa)
    - Usa f√≥rmula de Haversine para dist√¢ncia entre coordenadas
    
    Args:
        df: DataFrame com colunas 'user_id', 'latitude', 'longitude'
    
    Returns:
        Series com dist√¢ncia em km
    """
    df = df.copy()
    
    # Definir localiza√ß√£o "home" como primeira transa√ß√£o do usu√°rio
    home_locations = df.groupby('user_id').first()[['latitude', 'longitude']]
    home_locations.columns = ['home_lat', 'home_lon']
    
    # Merge de volta no dataframe
    df = df.merge(home_locations, left_on='user_id', right_index=True, how='left')
    
    # Calcular dist√¢ncia usando Haversine
    def haversine_distance(row):
        if pd.isna(row['home_lat']) or pd.isna(row['latitude']):
            return 0
        
        try:
            home = (row['home_lat'], row['home_lon'])
            current = (row['latitude'], row['longitude'])
            return geodesic(home, current).kilometers
        except:
            return 0
    
    df['distance_from_home_km'] = df.apply(haversine_distance, axis=1)
    
    return df['distance_from_home_km']


def calculate_velocity_between_transactions(df: pd.DataFrame) -> pd.Series:
    """
    Calcula velocidade (em km/h) necess√°ria para viajar entre duas transa√ß√µes consecutivas.
    
    DETECTA: Teleporte (velocidade humanamente imposs√≠vel, ex: 5000 km/h)
    
    L√ìGICA:
    - Velocidade = Dist√¢ncia / Tempo
    - Se velocidade > 800 km/h (velocidade de avi√£o), √© suspeito
    
    Args:
        df: DataFrame com colunas 'user_id', 'latitude', 'longitude', 'timestamp'
    
    Returns:
        Series com velocidade em km/h
    """
    df = df.copy()
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df = df.sort_values(['user_id', 'timestamp'])
    
    # Calcular coordenadas da transa√ß√£o anterior
    df['prev_lat'] = df.groupby('user_id')['latitude'].shift(1)
    df['prev_lon'] = df.groupby('user_id')['longitude'].shift(1)
    df['prev_timestamp'] = df.groupby('user_id')['timestamp'].shift(1)
    
    # Calcular dist√¢ncia entre transa√ß√µes
    def distance_between_txs(row):
        if pd.isna(row['prev_lat']):
            return 0
        
        try:
            prev = (row['prev_lat'], row['prev_lon'])
            current = (row['latitude'], row['longitude'])
            return geodesic(prev, current).kilometers
        except:
            return 0
    
    df['distance_between_txs'] = df.apply(distance_between_txs, axis=1)
    
    # Calcular tempo entre transa√ß√µes (em horas)
    df['time_between_txs_hours'] = (df['timestamp'] - df['prev_timestamp']).dt.total_seconds() / 3600
    
    # Calcular velocidade (evitar divis√£o por zero)
    df['velocity_kmh'] = np.where(
        df['time_between_txs_hours'] > 0,
        df['distance_between_txs'] / df['time_between_txs_hours'],
        0
    )
    
    # Limitar velocidades irrealistas (max: velocidade do som ~1200 km/h)
    df['velocity_kmh'] = df['velocity_kmh'].clip(upper=10000)
    
    # Primeira transa√ß√£o de cada usu√°rio = 0
    df['velocity_kmh'] = df['velocity_kmh'].fillna(0)
    
    return df['velocity_kmh']


def calculate_unusual_hour_flag(df: pd.DataFrame) -> pd.Series:
    """
    Flag (0/1) indicando se transa√ß√£o ocorreu fora do hor√°rio comum (madrugada).
    
    DETECTA: Hor√°rio at√≠pico (transa√ß√µes √†s 2-4 AM)
    
    Args:
        df: DataFrame com coluna 'timestamp'
    
    Returns:
        Series bin√°ria (1 = fora do hor√°rio, 0 = hor√°rio normal)
    """
    df = df.copy()
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    # Extrair hora
    df['hour'] = df['timestamp'].dt.hour
    
    # Hor√°rio at√≠pico: 0h-5h (madrugada)
    df['is_unusual_hour'] = ((df['hour'] >= 0) & (df['hour'] < 5)).astype(int)
    
    return df['is_unusual_hour']


def calculate_spending_deviation(df: pd.DataFrame, user_avg: pd.Series, user_std: pd.Series) -> pd.Series:
    """
    Calcula z-score do valor da transa√ß√£o em rela√ß√£o ao padr√£o do usu√°rio.
    
    DETECTA: Gasto s√∫bito (valor muito fora do padr√£o)
    
    Z-score > 3 = muito acima da m√©dia (suspeito!)
    
    Args:
        df: DataFrame com coluna 'amount'
        user_avg: M√©dia de gasto do usu√°rio
        user_std: Desvio padr√£o de gasto do usu√°rio
    
    Returns:
        Series com z-score
    """
    # Evitar divis√£o por zero
    user_std_safe = user_std.replace(0, 1)
    
    z_score = (df['amount'] - user_avg) / user_std_safe
    
    return z_score


def extract_temporal_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    Extrai features temporais: hora, dia da semana, fim de semana.
    
    Args:
        df: DataFrame com coluna 'timestamp'
    
    Returns:
        DataFrame com 3 novas colunas
    """
    df = df.copy()
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    df['hour_of_day'] = df['timestamp'].dt.hour
    df['day_of_week'] = df['timestamp'].dt.dayofweek  # 0=Monday, 6=Sunday
    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
    
    return df[['hour_of_day', 'day_of_week', 'is_weekend']]


def build_all_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    Aplica TODAS as transforma√ß√µes de features no dataset.
    
    Esta √© a fun√ß√£o principal que ser√° usada em:
    - EDA (Fase 3)
    - Treino do modelo (Fase 4)
    - API de produ√ß√£o (Fase 5)
    
    Args:
        df: DataFrame bruto com transa√ß√µes
    
    Returns:
        DataFrame com features adicionadas
    """
    print("üîß Iniciando Feature Engineering...")
    
    df = df.copy()
    
    # 1. Tempo desde √∫ltima transa√ß√£o
    print("  - Calculando tempo desde √∫ltima transa√ß√£o...")
    df['time_since_last_tx_sec'] = calculate_time_since_last_transaction(df)
    
    # 2. Estat√≠sticas de gasto do usu√°rio
    print("  - Calculando m√©dia e desvio padr√£o de gasto...")
    df['user_avg_amount_7d'], df['user_std_amount_7d'] = calculate_user_spending_stats(df)
    
    # 3. Dist√¢ncia de casa
    print("  - Calculando dist√¢ncia da localiza√ß√£o home...")
    df['distance_from_home_km'] = calculate_distance_from_home(df)
    
    # 4. Velocidade entre transa√ß√µes
    print("  - Calculando velocidade entre transa√ß√µes...")
    df['velocity_kmh'] = calculate_velocity_between_transactions(df)
    
    # 5. Flag de hor√°rio at√≠pico
    print("  - Detectando hor√°rios at√≠picos...")
    df['is_unusual_hour'] = calculate_unusual_hour_flag(df)
    
    # 6. Desvio de gasto (z-score)
    print("  - Calculando desvio de gasto...")
    df['spending_zscore'] = calculate_spending_deviation(
        df, 
        df['user_avg_amount_7d'], 
        df['user_std_amount_7d']
    )
    
    # 7. Features temporais
    print("  - Extraindo features temporais...")
    temporal_features = extract_temporal_features(df)
    df = pd.concat([df, temporal_features], axis=1)
    
    print("‚úì Feature Engineering conclu√≠do!")
    print(f"  - Total de features criadas: 10")
    
    return df


def get_feature_columns() -> list:
    """
    Retorna lista de colunas de features para treino do modelo.
    
    IMPORTANTE: N√ÉO incluir colunas que podem vazar informa√ß√£o:
    - transaction_id (identificador √∫nico, sem valor preditivo)
    - user_id (identificador √∫nico, sem valor preditivo)
    - timestamp (usar apenas features derivadas: hour_of_day, day_of_week)
    - merchant_name (muitos valores √∫nicos, usar merchant_category)
    - is_fraud (target!)
    - fraud_type (target!)
    - fraud_difficulty (target!)
    
    Esta lista ser√° usada para:
    - Treinar o Isolation Forest
    - Fazer predi√ß√µes na API
    
    Returns:
        Lista de nomes de colunas
    """
    return [
        'amount',
        'time_since_last_tx_sec',
        'user_avg_amount_7d',
        'user_std_amount_7d',
        'distance_from_home_km',
        'velocity_kmh',
        'is_unusual_hour',
        'spending_zscore',
        'hour_of_day',
        'day_of_week',
        'is_weekend'
    ]


# ==============================================================================
# SCRIPT DE TESTE (Se executar este arquivo diretamente)
# ==============================================================================

if __name__ == '__main__':
    print("=" * 80)
    print("TESTE DE FEATURE ENGINEERING")
    print("=" * 80)
    
    # Carregar dados
    print("\nüìÇ Carregando dados...")
    df = pd.read_csv('../../data/raw/transactions_with_fraud.csv')
    print(f"  ‚úì {len(df):,} transa√ß√µes carregadas")
    
    # Aplicar features
    df_features = build_all_features(df)
    
    # Salvar dataset com features
    output_path = '../../data/processed/transactions_with_features.csv'
    df_features.to_csv(output_path, index=False)
    print(f"\nüíæ Dataset com features salvo em: {output_path}")
    
    # Mostrar amostra de fraudes
    print("\nüîç Amostra de fraudes com features:")
    frauds = df_features[df_features['is_fraud'] == 1].head(5)
    feature_cols = get_feature_columns()
    print(frauds[['transaction_id', 'fraud_type', 'fraud_difficulty'] + feature_cols])
    
    print("\n" + "=" * 80)
    print("‚úì TESTE CONCLU√çDO COM SUCESSO!")
    print("=" * 80)